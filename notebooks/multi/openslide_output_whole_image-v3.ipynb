{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import argparse\n",
    "\n",
    "\n",
    "import sklearn.feature_extraction.image\n",
    "\n",
    "import matplotlib.cm\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.models import DenseNet\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from  skimage.color import rgb2gray\n",
    "\n",
    "os.environ['PATH'] = 'C:\\\\research\\\\openslide\\\\bin' + ';' + os.environ['PATH'] #can either specify openslide bin path in PATH, or add it dynamically\n",
    "import openslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Make output for entire image using Unet')\n",
    "parser.add_argument('input_pattern',\n",
    "                    help=\"input filename pattern. try: *.png, or tsv file containing list of files to analyze\",\n",
    "                    nargs=\"*\")\n",
    "\n",
    "parser.add_argument('-p', '--patchsize', help=\"patchsize, default 256\", default=256, type=int)\n",
    "parser.add_argument('-s', '--batchsize', help=\"batchsize for controlling GPU memory usage, default 10\", default=10, type=int)\n",
    "parser.add_argument('-o', '--outdir', help=\"outputdir, default ./output/\", default=\"./output/\", type=str)\n",
    "parser.add_argument('-r', '--resize', help=\"resize factor 1=1x, 2=2x, .5 = .5x\", default=1, type=float)\n",
    "parser.add_argument('-m', '--model', help=\"model\", default=\"best_model.pth\", type=str)\n",
    "parser.add_argument('-i', '--gpuid', help=\"id of gpu to use\", default=0, type=int)\n",
    "parser.add_argument('-f', '--force', help=\"force regeneration of output even if it exists\", default=False,\n",
    "                    action=\"store_true\")\n",
    "parser.add_argument('-b', '--basepath',\n",
    "                    help=\"base path to add to file names, helps when producing data using tsv file as input\",\n",
    "                    default=\"\", type=str)\n",
    "\n",
    "args = parser.parse_args([\"-mbrca1_densenet_best_model.pth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(args.gpuid if args.gpuid!=-2 and torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load(args.model, map_location=lambda storage, loc: storage) #load checkpoint to CPU and then put to device https://discuss.pytorch.org/t/saving-and-loading-torch-models-on-2-machines-with-different-number-of-gpu-devices/6666\n",
    "model = DenseNet(growth_rate=checkpoint[\"growth_rate\"], block_config=checkpoint[\"block_config\"],\n",
    "                 num_init_features=checkpoint[\"num_init_features\"], bn_size=checkpoint[\"bn_size\"],\n",
    "                 drop_rate=checkpoint[\"drop_rate\"], num_classes=checkpoint[\"num_classes\"]).to(device)\n",
    "model.load_state_dict(checkpoint[\"model_dict\"])\n",
    "model.eval()\n",
    "print(f\"total params: \\t{sum([np.prod(p.size()) for p in model.parameters()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fname=r\"D:\\research\\brca1\\mib1\\BRCA03_MIB1.mrxs\"\n",
    "osh  = openslide.OpenSlide(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osh.level_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_batch(l, n): \n",
    "    for i in range(0, l.shape[0], n):  \n",
    "        yield l[i:i + n,::] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add mask creation which skips parts of image\n",
    "mask_level = 8\n",
    "img = osh.read_region((0, 0), mask_level, osh.level_dimensions[mask_level])\n",
    "img = np.asarray(img)[:, :, 0:3]\n",
    "imgg=rgb2gray(img)\n",
    "mask=np.bitwise_and(imgg>0 ,imgg <200/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blue, orange, green, red\n",
    "#\"Stroma\",\"Tumor\",\"Immune cells\",\"Other\"]\n",
    "cmap= matplotlib.cm.tab10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level=0\n",
    "ds=int(osh.level_downsamples[level])\n",
    "\n",
    "patch_size=256\n",
    "stride_size=patch_size//4\n",
    "tile_size=stride_size*8*2\n",
    "tile_pad=patch_size-stride_size\n",
    "nclasses=3\n",
    "batch_size=64 #should be a power of 2\n",
    "\n",
    "\n",
    "shape=osh.level_dimensions[level]\n",
    "shaperound=[((d//tile_size)+1)*tile_size for d in shape]\n",
    "\n",
    "#npmm = np.memmap('npmm9.dat',mode='w+', dtype=np.uint8,shape=(osh.level_dimensions[dim][1]//patch_size,osh.level_dimensions[dim][0]//patch_size,3))\n",
    "#npmm=np.zeros((osh.level_dimensions[dim][1]//patch_size,osh.level_dimensions[dim][0]//patch_size,3))\n",
    "npmm=np.zeros((shaperound[1]//stride_size,shaperound[0]//stride_size,3),dtype=np.uint8)\n",
    "for y in tqdm(range(0,osh.level_dimensions[0][1],round(tile_size * osh.level_downsamples[level])), desc=\"outer\"):\n",
    "    for x in tqdm(range(0,osh.level_dimensions[0][0],round(tile_size * osh.level_downsamples[level])), desc=f\"innter {y}\", leave=False):\n",
    "\n",
    "        #if skip\n",
    "        \n",
    "        #maskx=int(x//(osh.level_dimensions[level][0]/osh.level_dimensions[mask_level][0]))\n",
    "        #masky=int(y//(osh.level_dimensions[level][1]/osh.level_dimensions[mask_level][1]))\n",
    "        \n",
    "        maskx=int(x//osh.level_downsamples[mask_level])\n",
    "        masky=int(y//osh.level_downsamples[mask_level])\n",
    "        \n",
    "        \n",
    "        if(maskx>= mask.shape[1] or masky>= mask.shape[0] or not mask[masky,maskx]): #need to handle rounding error \n",
    "            continue\n",
    "        \n",
    "        \n",
    "        output = np.zeros((0,nclasses,patch_size//patch_size,patch_size//patch_size))\n",
    "        io = np.asarray(osh.read_region((x, y), level, (tile_size+tile_pad,tile_size+tile_pad)))[:,:,0:3] #trim alpha\n",
    "        \n",
    "        arr_out=sklearn.feature_extraction.image.extract_patches(io,(patch_size,patch_size,3),stride_size)\n",
    "        arr_out_shape = arr_out.shape\n",
    "        arr_out = arr_out.reshape(-1,patch_size,patch_size,3)\n",
    "        \n",
    "        for batch_arr in divide_batch(arr_out,batch_size):\n",
    "        \n",
    "            arr_out_gpu = torch.from_numpy(batch_arr.transpose(0, 3, 1, 2) / 255).type('torch.FloatTensor').to(device)\n",
    "\n",
    "            # ---- get results\n",
    "            output_batch = model(arr_out_gpu)\n",
    "\n",
    "             # --- pull from GPU and append to rest of output \n",
    "            output_batch = output_batch.detach().cpu().numpy()\n",
    "#            a = batch_arr.reshape(batch_arr.shape[0],-1,arr_out.shape[-1])\n",
    "#            output_batch=a.mean(axis=1)[:,:,None,None]\n",
    "            output_batch_color=cmap(output_batch.argmax(axis=1), alpha=None)[:,0:3]\n",
    "            output = np.append(output,output_batch_color[:,:,None,None],axis=0)\n",
    "        \n",
    "        output = output.transpose((0, 2, 3, 1))\n",
    "        #turn from a single list into a matrix of tiles\n",
    "        output = output.reshape(arr_out_shape[0],arr_out_shape[1],patch_size//patch_size,patch_size//patch_size,output.shape[3])\n",
    "        \n",
    "        #turn all the tiles into an image\n",
    "        output=np.concatenate(np.concatenate(output,1),1)\n",
    "        #print(y//stride_size//ds,y//stride_size//ds+tile_size//stride_size,x//stride_size//ds,x//stride_size//ds+tile_size//stride_size)\n",
    "        npmm[y//stride_size//ds:y//stride_size//ds+tile_size//stride_size,x//stride_size//ds:x//stride_size//ds+tile_size//stride_size,:]=output*255 #need to save uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.external.tifffile import TiffWriter\n",
    "with TiffWriter('redux_s4xx.tif', bigtiff=True, imagej=True) as tif:\n",
    "    tif.save(npmm, compress=6, tile=(256,256) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npmm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f doit doit()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
