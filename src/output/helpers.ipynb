{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Output for the Multiresolution Network\n",
    "\n",
    "The network definition is stored in the module **MultiResSmallNetwork** in the directory src/models/\n",
    "\n",
    "In this Notebook, we want to generate the output for a part of an WSI at 5x. We start by specifying some global variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import argparse\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "from skimage import color \n",
    "\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "import sklearn.feature_extraction.image\n",
    "\n",
    "import matplotlib.cm\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from  skimage.color import rgb2gray\n",
    "import PIL\n",
    "\n",
    "import glob\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "from skimage.color import rgb2gray, rgb2hed\n",
    "\n",
    "from skimage.measure import * \n",
    "from skimage.filters import *\n",
    "from skimage.morphology import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_batch(l, n): \n",
    "    for i in range(0, l.shape[0], n):  \n",
    "        yield l[i:i + n,::] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to make output from the image, mask, set of points\n",
    "def MakeOutput(model, device, img, centers, patch_size, patch_size_res2, batch_size):\n",
    "    npatches=len(centers)\n",
    "    arr_out_res1 = np.zeros((npatches,3,patch_size,patch_size))\n",
    "    arr_out_res2 = np.zeros((npatches,3,patch_size,patch_size))\n",
    "    img_transform = Compose([\n",
    "       ToTensor()\n",
    "    ])\n",
    "    rs=[]\n",
    "    cs=[]\n",
    "    for i, (r, c) in tqdm(enumerate(centers), total = len(centers)):\n",
    "        r=int(round(r))\n",
    "        c=int(round(c))\n",
    "        rs.append(r)\n",
    "        cs.append(c)\n",
    "\n",
    "        imgres1 = img[r-patch_size//2:r+patch_size//2,c-patch_size//2:c+patch_size//2,:]\n",
    "            \n",
    "        imgres2 = img[r-patch_size_res2//2:r+patch_size_res2//2,c-patch_size_res2//2:c+patch_size_res2//2,:]\n",
    "        imgres2 = cv2.resize(imgres2,(patch_size,patch_size), interpolation=PIL.Image.BICUBIC) #resize it as specified above\n",
    "\n",
    "    \n",
    "        arr_out_res1[i,:,:,:] = img_transform(image=imgres1)[\"image\"]\n",
    "        arr_out_res2[i,:,:,:] = img_transform(image=imgres2)[\"image\"]\n",
    "    clusterids = []\n",
    "    for batch_arr_res1, batch_arr_res2 in tqdm(zip(divide_batch(arr_out_res1,batch_size),divide_batch(arr_out_res2,batch_size))):\n",
    "\n",
    "        #arr_out_gpu = torch.from_numpy(batch_arr.transpose(0, 3, 1, 2) / 255).type('torch.FloatTensor').to(device)\n",
    "        arr_out_gpu_res1 =  torch.from_numpy(batch_arr_res1).type('torch.FloatTensor').to(device)\n",
    "        arr_out_gpu_res2 =  torch.from_numpy(batch_arr_res2).type('torch.FloatTensor').to(device)\n",
    "\n",
    "        # ---- get results\n",
    "        clusterids.append(torch.argmax( model.dualfoward(arr_out_gpu_res1,arr_out_gpu_res2),dim=1).detach().cpu().numpy())\n",
    "    clusterids=np.hstack(clusterids)\n",
    "    return clusterids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OutputMasks(mask, regions, centers, index, clusterids):\n",
    "    result = np.zeros(mask.shape, dtype=int)\n",
    "    for i in range(len(index)):\n",
    "        for coord in list(regions[index[i]].coords):\n",
    "            r, c = coord\n",
    "            result[r, c] = clusterids[i] + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(img, resize, mirror_pad_size, patch_size_res2):\n",
    "    img= cv2.resize(img,(0,0),fx=resize,fy=resize, interpolation=PIL.Image.BICUBIC) #resize it as specified above\n",
    "    img = np.pad(img, [(mirror_pad_size, mirror_pad_size), (mirror_pad_size, mirror_pad_size), (0, 0)], mode=\"reflect\")\n",
    "    #create the coresponding mask by using hematoxylin\n",
    "    #hed=rgb2hed(img)\n",
    "    mask=img[:, :, 2] < 241\n",
    "    # remove the region near the edge\n",
    "    mask[0:patch_size_res2,:]=0\n",
    "    mask[:,0:patch_size_res2]=0\n",
    "    mask[:,-patch_size_res2-1:]=0\n",
    "    mask[-patch_size_res2-1:,:]=0\n",
    "    mask=remove_small_objects(mask,150)\n",
    "\n",
    "    mask[img.sum(axis=2)<100]=0\n",
    "\n",
    "    mask[img.sum(axis=2)>700]=0\n",
    "\n",
    "    \n",
    "    return img, mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CentersSLIC(regions, mask): \n",
    "    centers = []\n",
    "    index = []\n",
    "    for i, region in enumerate(regions):\n",
    "        (r, c) = region.centroid\n",
    "        r, c = int(round(r)), int(round(c))\n",
    "        if mask[r, c]!=0: \n",
    "            index.append(i)\n",
    "            centers.append((r, c))\n",
    "    return index, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Intersection(lst1, lst2):  \n",
    "    return list(set(lst1) & set(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveList(myList,filename):\n",
    "    # the filename should mention the extension 'npy'\n",
    "    np.save(filename,myList)\n",
    "    print(\"Saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadList(filename):\n",
    "    # the filename should mention the extension 'npy'\n",
    "    tempNumpyArray=np.load(filename)\n",
    "    return tempNumpyArray.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
